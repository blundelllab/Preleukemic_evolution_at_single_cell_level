{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ef0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json, re, glob,random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491f83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue1 = '#eff3ff'\n",
    "blue2 = '#bdd7e7'\n",
    "blue3 = '#6baed6'\n",
    "blue4 = '#3182bd'\n",
    "blue5 = '#08519c'\n",
    "green1 = '#edf8e9'\n",
    "green2 = '#bae4b3'\n",
    "green3 = '#74c476'\n",
    "green4 = '#31a354'\n",
    "green5 = '#006d2c'\n",
    "grey1 = '#f7f7f7'\n",
    "grey2 = '#cccccc'\n",
    "grey3 = '#969696'\n",
    "grey4 = '#636363'\n",
    "grey5 = '#252525'\n",
    "purple1 = '#f2f0f7'\n",
    "purple2 = '#cbc9e2'\n",
    "purple3 = '#9e9ac8'\n",
    "purple4 = '#756bb1'\n",
    "purple5 = '#54278f'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2786a53",
   "metadata": {},
   "source": [
    "# Extracting clone size vectors from virtual AMLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc69a8",
   "metadata": {},
   "source": [
    "We extract clone size vectors from the pickle dictionaries generated from our simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e229d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_size_trajectory(clones, T):\n",
    "    \n",
    "    total_population_size_traj=np.zeros(T)\n",
    "    for clone_id, clone_entry in clones.items():\n",
    "        total_population_size_traj=total_population_size_traj+clone_entry['clone_size_trajectory']\n",
    "\n",
    "    return total_population_size_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8e772",
   "metadata": {},
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795132f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['$n_0$','$n_1$','$n_2$','$n_3$','N', 'k', 'params_label'])\n",
    "# dd2=0\n",
    "\n",
    "threehitfiles = glob.glob('delta_DFE_simulations_April2024//k_3//mu_s_1times10minus5_30p*//*')\n",
    "params_label = 's30/mu10minus5'   \n",
    "\n",
    "cc = 0\n",
    "dd = 0\n",
    "for filename in threehitfiles[1::]:\n",
    "    with open(filename, 'rb') as handle:\n",
    "        imported_simulated_cases = pickle.load(handle)\n",
    "\n",
    "    dt=0.1\n",
    "    T = 800\n",
    "    clone_freq_threshold=0.1\n",
    "\n",
    "    \n",
    "    for sim_id, sim_info in imported_simulated_cases.items():\n",
    "\n",
    "        if cc>0:\n",
    "\n",
    "            n0 = -100\n",
    "            n1 = -100\n",
    "            n2 = -100\n",
    "            n3 = -100\n",
    "            n4 = -100\n",
    "        #     print('sim_id', sim_id)\n",
    "\n",
    "            clones=sim_info['clones']\n",
    "            dx_time=sim_info['diagnosis_time']\n",
    "        #     print(clones)\n",
    "        #     print('Dx time = ', dx_time)\n",
    "\n",
    "            main_branch_clones=[]\n",
    "            for clone_id, clone_info in clones.items():\n",
    "        #         print('clone:', clone_id)\n",
    "\n",
    "                mutations=clone_info['mutations']\n",
    "                driver_number=len(mutations)\n",
    "                if driver_number==3 and clone_info['aml_clone']:\n",
    "        #                 print(mutations)\n",
    "                    for m_id, s in mutations.items():\n",
    "                        main_branch_clones.append(m_id)\n",
    "\n",
    "            pop_size_traj=population_size_trajectory(clones, T)\n",
    "            total_N = pop_size_traj[int((dx_time)/dt)]\n",
    "    #         print('total N', total_N, 'main_branch_clones', main_branch_clones)\n",
    "        #     pop_size_traj=pop_size_traj+0.1 #avoid division by zero when AML emerges and population ceases to exsit\n",
    "        #     print(pop_size_traj)\n",
    "\n",
    "            branched_at_single_mutant_level=0\n",
    "            branched_at_double_mutant_level=0\n",
    "            branched_at_triple_mutant_level=0\n",
    "\n",
    "            for clone_id, clone_info in clones.items():\n",
    "        #             print('clone:', clone_id)\n",
    "\n",
    "                mutations=clone_info['mutations']\n",
    "\n",
    "                driver_number=len(mutations)\n",
    "\n",
    "                clonal_trajectory_of_clone = clone_info['clone_size_trajectory']\n",
    "\n",
    "        #         frequency_trajectory_of_clone=clone_info['clone_size_trajectory']/pop_size_traj\n",
    "        #         max_freq_clone=np.max(frequency_trajectory_of_clone)\n",
    "\n",
    "                if driver_number == 0:\n",
    "                    n0 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n0', n0)\n",
    "\n",
    "                if clone_id in main_branch_clones:\n",
    "\n",
    "                    if driver_number == 1:\n",
    "                        n1 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n1', n1)\n",
    "                    if driver_number == 2:\n",
    "                        n2 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n2', n2)\n",
    "                    if driver_number == 3:\n",
    "                        n3 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n3', n3)\n",
    "        #             if driver_number == 4:\n",
    "        #                 n4 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n4', n4)\n",
    "            if len(main_branch_clones)!=0:\n",
    "                df.loc[dd2] = [n0,n1,n2,n3,total_N,'3',params_label]\n",
    "    #         print('total N', total_N, 'main_branch_sum', n0+n1+n2+n3)\n",
    "        #     print([n0,n1,n2,n3,total_N,'3',params_label])\n",
    "                dd+=1\n",
    "                dd2+=1\n",
    "        cc+=1\n",
    "        \n",
    "        if dd >= 4000:\n",
    "            break\n",
    "            \n",
    "    if dd >= 4000:\n",
    "            break\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d116f5",
   "metadata": {},
   "source": [
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6721f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['$n_0$','$n_1$','$n_2$','$n_3$','$n_4$','N', 'k', 'params_label'])\n",
    "# dd2=0\n",
    "\n",
    "threehitfiles = glob.glob('delta_DFE_simulations_April2024//k_4//mu_s_1times10minus5_30p*//*')\n",
    "params_label = 's30/mu10minus5'   \n",
    "\n",
    "cc = 0\n",
    "dd = 0\n",
    "for filename in threehitfiles[1::]:\n",
    "    with open(filename, 'rb') as handle:\n",
    "        imported_simulated_cases = pickle.load(handle)\n",
    "\n",
    "    dt=0.1\n",
    "    T = 800\n",
    "    clone_freq_threshold=0.1\n",
    "\n",
    "    \n",
    "    for sim_id, sim_info in imported_simulated_cases.items():\n",
    "\n",
    "        if cc>0:\n",
    "\n",
    "            n0 = -100\n",
    "            n1 = -100\n",
    "            n2 = -100\n",
    "            n3 = -100\n",
    "            n4 = -100\n",
    "        #     print('sim_id', sim_id)\n",
    "\n",
    "            clones=sim_info['clones']\n",
    "            dx_time=sim_info['diagnosis_time']\n",
    "        #     print(clones)\n",
    "        #     print('Dx time = ', dx_time)\n",
    "\n",
    "            main_branch_clones=[]\n",
    "            for clone_id, clone_info in clones.items():\n",
    "        #         print('clone:', clone_id)\n",
    "\n",
    "                mutations=clone_info['mutations']\n",
    "                driver_number=len(mutations)\n",
    "                if driver_number==4 and clone_info['aml_clone']:\n",
    "        #                 print(mutations)\n",
    "                    for m_id, s in mutations.items():\n",
    "                        main_branch_clones.append(m_id)\n",
    "\n",
    "            pop_size_traj=population_size_trajectory(clones, T)\n",
    "            total_N = pop_size_traj[int((dx_time)/dt)]\n",
    "    #         print('total N', total_N, 'main_branch_clones', main_branch_clones)\n",
    "        #     pop_size_traj=pop_size_traj+0.1 #avoid division by zero when AML emerges and population ceases to exsit\n",
    "        #     print(pop_size_traj)\n",
    "\n",
    "            branched_at_single_mutant_level=0\n",
    "            branched_at_double_mutant_level=0\n",
    "            branched_at_triple_mutant_level=0\n",
    "\n",
    "            for clone_id, clone_info in clones.items():\n",
    "        #             print('clone:', clone_id)\n",
    "\n",
    "                mutations=clone_info['mutations']\n",
    "\n",
    "                driver_number=len(mutations)\n",
    "\n",
    "                clonal_trajectory_of_clone = clone_info['clone_size_trajectory']\n",
    "\n",
    "        #         frequency_trajectory_of_clone=clone_info['clone_size_trajectory']/pop_size_traj\n",
    "        #         max_freq_clone=np.max(frequency_trajectory_of_clone)\n",
    "\n",
    "                if driver_number == 0:\n",
    "                    n0 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n0', n0)\n",
    "\n",
    "                if clone_id in main_branch_clones:\n",
    "\n",
    "                    if driver_number == 1:\n",
    "                        n1 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n1', n1)\n",
    "                    if driver_number == 2:\n",
    "                        n2 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n2', n2)\n",
    "                    if driver_number == 3:\n",
    "                        n3 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n3', n3)\n",
    "                    if driver_number == 4:\n",
    "                        n4 = clonal_trajectory_of_clone[int((dx_time)/dt)]\n",
    "        #                 print('n4', n4)\n",
    "            if len(main_branch_clones)!=0:\n",
    "                df.loc[dd2] = [n0,n1,n2,n3,n4,total_N,'4',params_label]\n",
    "    #         print('total N', total_N, 'main_branch_sum', n0+n1+n2+n3)\n",
    "        #     print([n0,n1,n2,n3,total_N,'3',params_label])\n",
    "                dd+=1\n",
    "                dd2+=1\n",
    "        cc+=1\n",
    "        \n",
    "        if dd >= 1000:\n",
    "            break\n",
    "            \n",
    "    if dd >= 1000:\n",
    "            break\n",
    "# df.to_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_no_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3726b4",
   "metadata": {},
   "source": [
    "# Import real clone size vectors from Poon et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "c2ed8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = {'s0/mu10minus4':0, 's15/mu10minus4':1, 's30/mu10minus4':2,\\\n",
    "              's0/mu10minus5':3, 's15/mu10minus5':4, 's30/mu10minus5':5,\\\n",
    "              's0/mu10minus6':6, 's15/mu10minus6':7, 's30/mu10minus6':8}\n",
    "colour_list = ['#ffeda0', '#feb24c', '#f03b20', '#e5f5e0', '#a1d99b', '#31a354', '#deebf7', '#9ecae1', '#3182bd']\n",
    "\n",
    "legend_map = {}\n",
    "for label, ind in map.items():\n",
    "    legend_map[label] = colour_list[map[label]]\n",
    "    \n",
    "def custom_labelizer(label_tuple, width, height):\n",
    "    (label, ) =label_tuple\n",
    "    return (0, 0), colour_list[map[label_tuple]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980ebe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Create an empty DataFrame\n",
    "# df = pd.DataFrame(columns=['$n_0$','$n_1$','$n_2$','$n_3$','total_n', 'k', 'sample_label'])\n",
    "\n",
    "# # Append rows one by one\n",
    "# df = df.append({'$n_0$': 680, '$n_1$':  50, '$n_2$':  0,'$n_3$':8,'total_n':680+50+0+8+160+50,'k':4,'sample_label':'7322'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 537, '$n_1$':  5, '$n_2$':  159,'$n_3$':0,'total_n':537+5+159+0,'k':4,'sample_label':'25568R'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 0, '$n_1$':  0, '$n_2$':  43,'$n_3$':120,'total_n':43+120+36+67+363,'k':4,'sample_label':'7328'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 5, '$n_1$':  0, '$n_2$':  0,'$n_3$':6,'total_n':5+6+33,'k':4,'sample_label':'27510'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 21, '$n_1$':  0, '$n_2$':  15,'$n_3$':3,'total_n':21+0+15+3,'k':4,'sample_label':'2261'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 6, '$n_1$':  0, '$n_2$':  4,'$n_3$':0,'total_n':6+0+4,'k':4,'sample_label':'47668'}, ignore_index=True)\n",
    "\n",
    "\n",
    "# df = df.append({'$n_0$': 158, '$n_1$':  38, '$n_2$':  119,'$n_3$':'NaN', 'total_n':158+38+119+7, 'k':3,'sample_label':'2225'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 28, '$n_1$':  20, '$n_2$':  0,'$n_3$':'NaN','total_n':28+20+0+10+5,'k':3,'sample_label':'27491'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 0, '$n_1$':  0, '$n_2$':  0,'$n_3$':'NaN','total_n':25,'k':3,'sample_label': '4334'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 2, '$n_1$':  0, '$n_2$':  3,'$n_3$':'NaN','total_n':5,'k':3,'sample_label':'26833R'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 13, '$n_1$':  3, '$n_2$':  1,'$n_3$':'NaN','total_n':13+3+1,'k':3,'sample_label':'12565b'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 285, '$n_1$':  0, '$n_2$':  13,'$n_3$':'NaN','total_n':285+13,'k':3,'sample_label':'12565a_v1'}, ignore_index=True)\n",
    "# df = df.append({'$n_0$': 285, '$n_1$':  13, '$n_2$':  0,'$n_3$':'NaN','total_n':285+13,'k':3,'sample_label':'12565a_v2'}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# # df.to_csv('dataframes_for_distance_metrics/Poon_unambiguous_cases_clone_size_vectors.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "b715baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3 7\n",
      "k=4 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_hit_linear_Poon['$f_0$'] = four_hit_linear_Poon['$n_0$']/(four_hit_linear_Poon['total_n'])\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_hit_linear_Poon['$f_1$'] = four_hit_linear_Poon['$n_1$']/(four_hit_linear_Poon['total_n'])\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_hit_linear_Poon['$f_2$'] = four_hit_linear_Poon['$n_2$']/(four_hit_linear_Poon['total_n'])\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_hit_linear_Poon['$f_3$'] = four_hit_linear_Poon['$n_3$']/(four_hit_linear_Poon['total_n'])\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  three_hit_linear_Poon['$f_0$'] = three_hit_linear_Poon['$n_0$']/(three_hit_linear_Poon['total_n'])\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  three_hit_linear_Poon['$f_1$'] = three_hit_linear_Poon['$n_1$']/(three_hit_linear_Poon['total_n'])\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2827080109.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  three_hit_linear_Poon['$f_2$'] = three_hit_linear_Poon['$n_2$']/(three_hit_linear_Poon['total_n'])\n"
     ]
    }
   ],
   "source": [
    "Poon_cases = pd.read_csv('dataframes_for_distance_metrics/Poon_unambiguous_cases_clone_size_vectors.csv')\n",
    "\n",
    "four_hit_linear_Poon = Poon_cases.loc[Poon_cases['k'] == 4]\n",
    "four_hit_linear_Poon['$f_0$'] = four_hit_linear_Poon['$n_0$']/(four_hit_linear_Poon['total_n'])\n",
    "four_hit_linear_Poon['$f_1$'] = four_hit_linear_Poon['$n_1$']/(four_hit_linear_Poon['total_n'])\n",
    "four_hit_linear_Poon['$f_2$'] = four_hit_linear_Poon['$n_2$']/(four_hit_linear_Poon['total_n'])\n",
    "four_hit_linear_Poon['$f_3$'] = four_hit_linear_Poon['$n_3$']/(four_hit_linear_Poon['total_n'])\n",
    "\n",
    "three_hit_linear_Poon = Poon_cases.loc[Poon_cases['k'] == 3]\n",
    "three_hit_linear_Poon['$f_0$'] = three_hit_linear_Poon['$n_0$']/(three_hit_linear_Poon['total_n'])\n",
    "three_hit_linear_Poon['$f_1$'] = three_hit_linear_Poon['$n_1$']/(three_hit_linear_Poon['total_n'])\n",
    "three_hit_linear_Poon['$f_2$'] = three_hit_linear_Poon['$n_2$']/(three_hit_linear_Poon['total_n'])\n",
    "\n",
    "\n",
    "\n",
    "print('k=3', len(three_hit_linear_Poon))\n",
    "print('k=4', len(four_hit_linear_Poon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd1379",
   "metadata": {},
   "source": [
    "# Import real clone size vectors from Morita et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "aef7a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = {'s0/mu10minus4':0, 's15/mu10minus4':1, 's30/mu10minus4':2,\\\n",
    "              's0/mu10minus5':3, 's15/mu10minus5':4, 's30/mu10minus5':5,\\\n",
    "              's0/mu10minus6':6, 's15/mu10minus6':7, 's30/mu10minus6':8}\n",
    "colour_list = ['#ffeda0', '#feb24c', '#f03b20', '#e5f5e0', '#a1d99b', '#31a354', '#deebf7', '#9ecae1', '#3182bd']\n",
    "\n",
    "legend_map = {}\n",
    "for label, ind in map.items():\n",
    "    legend_map[label] = colour_list[map[label]]\n",
    "    \n",
    "def custom_labelizer(label_tuple, width, height):\n",
    "    (label, ) =label_tuple\n",
    "    return (0, 0), colour_list[map[label_tuple]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "99262609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3 27\n",
      "k=4 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\220956390.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  three_hit_linear_morita['total_freq']=three_hit_linear_morita['$n_0$']+three_hit_linear_morita['$n_1$']+three_hit_linear_morita['$n_2$']\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\220956390.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_hit_linear_morita['total_freq']=four_hit_linear_morita['$n_0$']+four_hit_linear_morita['$n_1$']+four_hit_linear_morita['$n_2$']+four_hit_linear_morita['$n_3$']\n"
     ]
    }
   ],
   "source": [
    "morita_cases = pd.read_csv('dataframes_for_distance_metrics/Morita_linear_cases_clone_size_vectors_after_manual_filtering.csv')\n",
    "morita_cases = morita_cases.drop_duplicates()\n",
    "\n",
    "four_hit_linear_morita = morita_cases.loc[morita_cases['k'] == 4]\n",
    "three_hit_linear_morita = morita_cases.loc[morita_cases['k'] == 3]\n",
    "# three_hit_linear_morita.head(10)\n",
    "# total_freq excludes blasts\n",
    "three_hit_linear_morita['total_freq']=three_hit_linear_morita['$n_0$']+three_hit_linear_morita['$n_1$']+three_hit_linear_morita['$n_2$']\n",
    "four_hit_linear_morita['total_freq']=four_hit_linear_morita['$n_0$']+four_hit_linear_morita['$n_1$']+four_hit_linear_morita['$n_2$']+four_hit_linear_morita['$n_3$']\n",
    "# three_hit_linear_morita.head(10)\n",
    "print('k=3', len(three_hit_linear_morita))\n",
    "print('k=4', len(four_hit_linear_morita))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f723e",
   "metadata": {},
   "source": [
    "Beware that the wildtype frequency in branched cases contains the side branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b4d9907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3 17\n",
      "k=4 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2603737195.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  three_hit_branched_morita['total_freq']=three_hit_branched_morita['$n_0$']+three_hit_branched_morita['$n_1$']+three_hit_branched_morita['$n_2$']\n",
      "C:\\Users\\chickchick\\AppData\\Local\\Temp\\ipykernel_40480\\2603737195.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_hit_branched_morita['total_freq']=four_hit_branched_morita['$n_0$']+four_hit_branched_morita['$n_1$']+four_hit_branched_morita['$n_2$']+four_hit_branched_morita['$n_3$']\n"
     ]
    }
   ],
   "source": [
    "morita_branched_cases = pd.read_csv('dataframes_for_distance_metrics/Morita_branched_cases_clone_size_vectors_after_manual_filtering.csv')\n",
    "morita_branched_cases = morita_branched_cases.drop_duplicates()\n",
    "\n",
    "four_hit_branched_morita = morita_branched_cases.loc[morita_branched_cases['k'] == 4]\n",
    "three_hit_branched_morita = morita_branched_cases.loc[morita_branched_cases['k'] == 3]\n",
    "# total_freq excludes blasts\n",
    "three_hit_branched_morita['total_freq']=three_hit_branched_morita['$n_0$']+three_hit_branched_morita['$n_1$']+three_hit_branched_morita['$n_2$']\n",
    "four_hit_branched_morita['total_freq']=four_hit_branched_morita['$n_0$']+four_hit_branched_morita['$n_1$']+four_hit_branched_morita['$n_2$']+four_hit_branched_morita['$n_3$']\n",
    "print('k=3', len(three_hit_branched_morita))\n",
    "print('k=4', len(four_hit_branched_morita))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bebd5e",
   "metadata": {},
   "source": [
    "# Implement similarity metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb34ce",
   "metadata": {},
   "source": [
    "k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "91680c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframes_for_distance_metrics/k_3_4000_clone_size_vectors_for_0_3_6_9_12_15_18_21_24_27_30_no_tree_comparison.csv')\n",
    "df['$f_0$'] = df['$n_0$']/(df['N'])\n",
    "df['$f_1$'] = df['$n_1$']/(df['N'])\n",
    "df['$f_2$'] = df['$n_2$']/(df['N'])\n",
    "df_k3_all_encompassing = df\n",
    "\n",
    "for index, row in three_hit_linear_morita.iterrows():\n",
    "    case_n0 = row['$n_0$']\n",
    "    case_n1 = row['$n_1$']\n",
    "    case_n2 = row['$n_2$']\n",
    "#     case_n3 = row['$n_3$']\n",
    "    sample_label=row['sample_label']\n",
    "\n",
    "#     df[str(sample_label)+' exp. diff']=  np.exp(-abs(df['$f_0$'] - case_n0)) + np.exp(-abs(df['$f_1$'] - case_n1)) + np.exp(-abs(df['$f_2$'] - case_n2)) \n",
    "    df_k3_all_encompassing[str(sample_label)+' exp. diff']=  np.exp(-abs(df_k3_all_encompassing['$f_0$'] - case_n0)) + np.exp(-abs(df_k3_all_encompassing['$f_1$'] - case_n1)) + np.exp(-abs(df_k3_all_encompassing['$f_2$'] - case_n2)) \n",
    "\n",
    "for index, row in three_hit_branched_morita.iterrows():\n",
    "    case_n0 = row['$n_0$']\n",
    "    case_n1 = row['$n_1$']\n",
    "    case_n2 = row['$n_2$']\n",
    "#     case_n3 = row['$n_3$']\n",
    "    sample_label=row['sample_label']\n",
    "\n",
    "#     df[str(sample_label)+' exp. diff']=  np.exp(-abs(df['$f_0$'] - case_n0)) + np.exp(-abs(df['$f_1$'] - case_n1)) + np.exp(-abs(df['$f_2$'] - case_n2)) \n",
    "    df_k3_all_encompassing[str(sample_label)+' exp. diff']=  np.exp(-abs(df_k3_all_encompassing['$f_0$'] - case_n0)) + np.exp(-abs(df_k3_all_encompassing['$f_1$'] - case_n1)) + np.exp(-abs(df_k3_all_encompassing['$f_2$'] - case_n2)) \n",
    "\n",
    "\n",
    "# df_k3_all_encompassing.to_csv('dataframes_for_distance_metrics/k_3_4000_clone_size_vectors_for_0_3_6_9_12_15_18_21_24_27_30_with_morita_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8aa7c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframes_for_distance_metrics/k_3_4000_clone_size_vectors_for_0_3_6_9_12_15_18_21_24_27_30_no_tree_comparison.csv')\n",
    "df['$f_0$'] = df['$n_0$']/(df['N'])\n",
    "df['$f_1$'] = df['$n_1$']/(df['N'])\n",
    "df['$f_2$'] = df['$n_2$']/(df['N'])\n",
    "df_k3_all_encompassing = df\n",
    "\n",
    "for index, row in three_hit_linear_Poon.iterrows():\n",
    "    case_n0 = row['$f_0$']\n",
    "    case_n1 = row['$f_1$']\n",
    "    case_n2 = row['$f_2$']\n",
    "#     case_n3 = row['$n_3$']\n",
    "    sample_label=row['sample_label']\n",
    "\n",
    "    df[str(sample_label)+' exp. diff']=  np.exp(-abs(df['$f_0$'] - case_n0)) + np.exp(-abs(df['$f_1$'] - case_n1)) + np.exp(-abs(df['$f_2$'] - case_n2)) \n",
    "    df_k3_all_encompassing[str(sample_label)+' exp. diff']=  np.exp(-abs(df_k3_all_encompassing['$f_0$'] - case_n0)) + np.exp(-abs(df_k3_all_encompassing['$f_1$'] - case_n1)) + np.exp(-abs(df_k3_all_encompassing['$f_2$'] - case_n2)) \n",
    "\n",
    "# df_k3_all_encompassing.to_csv('dataframes_for_distance_metrics/k_3_4000_clone_size_vectors_for_0_3_6_9_12_15_18_21_24_27_30_with_Poon_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5f2d5",
   "metadata": {},
   "source": [
    "k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "83c72c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframes_for_distance_metrics/k_4_4000_clone_size_vectors_for_9_12_15_18_21_24_27_30_no_tree_comparison.csv')\n",
    "df = pd.read_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_no_tree_comparison.csv')\n",
    "\n",
    "df['$f_0$'] = df['$n_0$']/(df['N'])\n",
    "df['$f_1$'] = df['$n_1$']/(df['N'])\n",
    "df['$f_2$'] = df['$n_2$']/(df['N'])\n",
    "df['$f_3$'] = df['$n_3$']/(df['N'])\n",
    "df_k4_all_encompassing = df\n",
    "\n",
    "for index, row in four_hit_linear_morita.iterrows():\n",
    "    case_n0 = row['$n_0$']\n",
    "    case_n1 = row['$n_1$']\n",
    "    case_n2 = row['$n_2$']\n",
    "    case_n3 = row['$n_3$']\n",
    "    sample_label=row['sample_label']\n",
    "\n",
    "#     df[str(sample_label)+' exp. diff']=  np.exp(-abs(df['$f_0$'] - case_n0)) + np.exp(-abs(df['$f_1$'] - case_n1)) + np.exp(-abs(df['$f_2$'] - case_n2)) \n",
    "    df_k4_all_encompassing[str(sample_label)+' exp. diff']=  np.exp(-abs(df_k4_all_encompassing['$f_0$'] - case_n0)) + np.exp(-abs(df_k4_all_encompassing['$f_1$'] - case_n1)) + np.exp(-abs(df_k4_all_encompassing['$f_2$'] - case_n2))  + np.exp(-abs(df_k4_all_encompassing['$f_3$'] - case_n3)) \n",
    "\n",
    "for index, row in four_hit_branched_morita.iterrows():\n",
    "    case_n0 = row['$n_0$']\n",
    "    case_n1 = row['$n_1$']\n",
    "    case_n2 = row['$n_2$']\n",
    "    case_n3 = row['$n_3$']\n",
    "    sample_label=row['sample_label']\n",
    "\n",
    "#     df[str(sample_label)+' exp. diff']=  np.exp(-abs(df['$f_0$'] - case_n0)) + np.exp(-abs(df['$f_1$'] - case_n1)) + np.exp(-abs(df['$f_2$'] - case_n2)) \n",
    "    df_k4_all_encompassing[str(sample_label)+' exp. diff']=  np.exp(-abs(df_k4_all_encompassing['$f_0$'] - case_n0)) + np.exp(-abs(df_k4_all_encompassing['$f_1$'] - case_n1)) + np.exp(-abs(df_k4_all_encompassing['$f_2$'] - case_n2))  + np.exp(-abs(df_k4_all_encompassing['$f_3$'] - case_n3)) \n",
    "\n",
    "# df_k4_all_encompassing.to_csv('dataframes_for_distance_metrics/k_4_4000_clone_size_vectors_for_9_12_15_18_21_24_27_30_with_morita_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n",
    "# df_k4_all_encompassing.to_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_with_morita_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "19ca9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframes_for_distance_metrics/k_4_4000_clone_size_vectors_for_9_12_15_18_21_24_27_30_no_tree_comparison.csv')\n",
    "df = pd.read_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_no_tree_comparison.csv')\n",
    "\n",
    "df['$f_0$'] = df['$n_0$']/(df['N'])\n",
    "df['$f_1$'] = df['$n_1$']/(df['N'])\n",
    "df['$f_2$'] = df['$n_2$']/(df['N'])\n",
    "df['$f_3$'] = df['$n_3$']/(df['N'])\n",
    "df_k4_all_encompassing = df\n",
    "for index, row in four_hit_linear_Poon.iterrows():\n",
    "    case_n0 = row['$f_0$']\n",
    "    case_n1 = row['$f_1$']\n",
    "    case_n2 = row['$f_2$']\n",
    "    case_n3 = row['$f_3$']\n",
    "    sample_label=row['sample_label']\n",
    "\n",
    "#     df[str(sample_label)+' exp. diff']=  np.exp(-abs(df['$f_0$'] - case_n0)) + np.exp(-abs(df['$f_1$'] - case_n1)) + np.exp(-abs(df['$f_2$'] - case_n2)) \n",
    "    df_k4_all_encompassing[str(sample_label)+' exp. diff']=  np.exp(-abs(df_k4_all_encompassing['$f_0$'] - case_n0)) + np.exp(-abs(df_k4_all_encompassing['$f_1$'] - case_n1)) + np.exp(-abs(df_k4_all_encompassing['$f_2$'] - case_n2))  + np.exp(-abs(df_k4_all_encompassing['$f_3$'] - case_n3)) \n",
    "    \n",
    "\n",
    "\n",
    "# df_k4_all_encompassing.to_csv('dataframes_for_distance_metrics/k_4_4000_clone_size_vectors_for_9_12_15_18_21_24_27_30_with_Poon_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n",
    "# df_k4_all_encompassing.to_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_with_Poon_tree_comparison.csv', sep=',', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8491c1",
   "metadata": {},
   "source": [
    "# Plotting most similar simulated trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "a9709bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_params_labels = ['s0/mu10minus5', 's3/mu10minus5', 's6/mu10minus5',\\\n",
    "                         's9/mu10minus5', 's12/mu10minus5', 's15/mu10minus5',\\\n",
    "                         's18/mu10minus5', 's21/mu10minus5','s24/mu10minus5',\\\n",
    "                        's27/mu10minus5','s30/mu10minus5']\n",
    "lower=-6\n",
    "med =-5\n",
    "higher =-4\n",
    "\n",
    "mapping = {(0,higher):'s0/mu10minus4',(0.03,higher):'s3/mu10minus4', (0.06,higher):'s6/mu10minus4', \\\n",
    "           (0.09,higher):'s9/mu10minus4', (0.12,higher):'s12/mu10minus4', (0.15, higher):'s15/mu10minus4',\\\n",
    "           (0.18, higher):'s18/mu10minus4',(0.21, higher): 's21/mu10minus4', (0.24, higher):'s24/mu10minus4',\\\n",
    "           (0.27, higher): 's27/mu10minus4', (0.30, higher):'s30/mu10minus4',\\\n",
    "             (0,med):'s0/mu10minus5', (0.03,med):'s3/mu10minus5',  (0.06,med):'s6/mu10minus5',\\\n",
    "           (0.09, med):'s9/mu10minus5', (0.12, med):'s12/mu10minus5', (0.15, med):'s15/mu10minus5',\\\n",
    "           (0.18, med):'s18/mu10minus5', (0.21, med):'s21/mu10minus5',(0.24, med):'s24/mu10minus5',\\\n",
    "           (0.27, med):'s27/mu10minus5', (0.30, med):'s30/mu10minus5'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c5637",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749e7fdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# k = 3\n",
    "df = pd.read_csv('dataframes_for_distance_metrics/k_3_4000_clone_size_vectors_for_0_3_6_9_12_15_18_21_24_27_30_with_morita_tree_comparison.csv')\n",
    "# df = pd.read_csv('dataframes_for_distance_metrics/k_3_4000_clone_size_vectors_for_0_3_6_9_12_15_18_21_24_27_30_with_Poon_tree_comparison.csv')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import matplotlib.patches as mpatches\n",
    "import statsmodels.graphics.mosaicplot as mp\n",
    "import matplotlib\n",
    "\n",
    "threshold = 100\n",
    "for index1, row1 in three_hit_branched_morita.iterrows():\n",
    "    sample_label=row1['sample_label']\n",
    "\n",
    "    sorted_df=df.sort_values(by = str(sample_label)+' exp. diff', ascending=False)\n",
    "    Closest_x_sim_trees = sorted_df[0:threshold]\n",
    "    params_of_closest_trees = Closest_x_sim_trees['params_label'].tolist()\n",
    "    params_label_counted = Counter(params_of_closest_trees)\n",
    "    \n",
    "    average_s = params_label_counted['s0/mu10minus5']*0+params_label_counted['s3/mu10minus5']*3+params_label_counted['s6/mu10minus5']*6+\\\n",
    "    params_label_counted['s9/mu10minus5']*9+params_label_counted['s12/mu10minus5']*12+\\\n",
    "    params_label_counted['s15/mu10minus5']*15+params_label_counted['s18/mu10minus5']*18+params_label_counted['s21/mu10minus5']*21+\\\n",
    "    params_label_counted['s24/mu10minus5']*24+params_label_counted['s27/mu10minus5']*27+params_label_counted['s30/mu10minus5']*30\n",
    "    Count_array = []\n",
    "    for s in [0,0.03,0.06,0.09,0.12,0.15,0.18, 0.21,0.24,0.27,0.30]:\n",
    "        mu_direction = []\n",
    "        for mu in [med,higher]:\n",
    "            print(mapping[(s, mu)])\n",
    "            try:\n",
    "                entry= params_label_counted[mapping[(s, mu)]]\n",
    "            except:\n",
    "                entry = 0\n",
    "            mu_direction.append(entry)\n",
    "        Count_array.append(mu_direction)\n",
    " \n",
    "    y, x = np.meshgrid([med,higher], [0,0.03,0.06,0.09,0.12,0.15,0.18, 0.21,0.24,0.27,0.30])\n",
    "    y, x = np.meshgrid([med,higher], [0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    f, ax = plt.subplots(1,1, figsize=(2.5,2.5))\n",
    "    font = {'weight' : 'normal','size'   : 25}\n",
    "    matplotlib.rc('font', **font)\n",
    "    f.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    for index, row in Closest_x_sim_trees.iterrows():\n",
    "#         tree = [row['$f_0$'],row['$f_1$'],row['$f_2$'],row['$f_3$']]\n",
    "        tree = [row['$f_0$'],row['$f_1$'],row['$f_2$']]\n",
    "        ax.plot(range(len(tree)), tree, color = grey2, zorder =0)\n",
    "        \n",
    "    ax.set_xticks(range(len(tree)))\n",
    "    ax.set_xticklabels(['$n_0$', '$n_1$', '$n_2$'])\n",
    "#     ax.set_xticklabels(['', '', ''])\n",
    "    \n",
    "    real_tree =  [row1['$n_0$'],row1['$n_1$'],row1['$n_2$']]\n",
    "#     real_tree =  [row1['$f_0$'],row1['$f_1$'],row1['$f_2$']]\n",
    "\n",
    "    ax.plot([0,1,2], real_tree, label=sample_label, color = purple5, zorder = 1, linewidth=4)\n",
    "\n",
    "    ax.set_yticks([0,max(real_tree)])\n",
    "    ax.set_yticklabels(['0',round(max(real_tree),1)],fontsize=20)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "#     ax.set_title(sample_label, fontsize=20)\n",
    "    morita_sample_label =sample_label.split('-')\n",
    "    ax.set_title('morita-'+morita_sample_label[1], fontsize=20)\n",
    "\n",
    "    \n",
    "    plt.savefig('dataframes_for_distance_metrics/individual_tree_variation/with_6p/top_100/'+str(average_s)+'_k_3_'+str(sample_label)+'tree.pdf', bbox_inches = 'tight')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    f, ax = plt.subplots(1,1, figsize=(2.5,1))\n",
    "#     f, ax = plt.subplots(1,1, figsize=(2.5*4,1))\n",
    "    font = {'weight' : 'normal','size'   : 25}\n",
    "    matplotlib.rc('font', **font)\n",
    "    f.subplots_adjust(wspace=0.4)\n",
    "    \n",
    "    \n",
    "    c = ax.pcolormesh(x, y, Count_array, cmap='copper',vmax=50)\n",
    "#     ax[1].set_title('Underlying parameter space')\n",
    "#     ax.set_xlabel('$s$', fontsize = 21)\n",
    "#     ax[1].set_ylabel('$\\mu$', fontsize = 21)\n",
    "    ax.set_ylim(-5.5,-4.5)\n",
    "    \n",
    "    y_major_ticks = []\n",
    "    y_major_tick_labels = []\n",
    "    x_major_ticks = []\n",
    "    x_major_tick_labels = []\n",
    "#     x_major_ticks = [0, 1,2,3,4,5,6,7,8,9,10]\n",
    "#     x_major_tick_labels = [\"0%\", \"3%\", \"6%\", \"9%\", \"12%\", \"15%\", \"18%\",  \"21%\", \"24%\", \"27%\",  \"30%\"]\n",
    "\n",
    "    \n",
    "    ax.set_yticks(y_major_ticks)\n",
    "    ax.set_yticklabels(y_major_tick_labels)\n",
    "    ax.set_xticks(x_major_ticks)\n",
    "    ax.set_xticklabels(x_major_tick_labels, fontsize=15)\n",
    "    ax.margins(x=0)\n",
    "    # set the limits of the plot to the limits of the data\n",
    "    # ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "#     plt.colorbar(c, ax=ax, label= '# of simulated trees')\n",
    "#     plt.colorbar.ax.set_ylabel()\n",
    "    \n",
    "    \n",
    "#     break\n",
    "#     plt.savefig('dataframes_for_distance_metrics/individual_tree_variation/with_6p/top_100/'+str(average_s)+'_k_3_'+str(sample_label)+'.pdf', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d718dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=4\n",
    "\n",
    "df = pd.read_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_with_morita_tree_comparison.csv')\n",
    "# df = pd.read_csv('dataframes_for_distance_metrics/k_4_1000_clone_size_vectors_for_6_9_12_15_18_21_24_27_30_with_Poon_tree_comparison.csv')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import matplotlib.patches as mpatches\n",
    "import statsmodels.graphics.mosaicplot as mp\n",
    "import matplotlib\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "for index1, row1 in four_hit_branched_morita.iterrows():\n",
    "    sample_label=row1['sample_label']\n",
    "    \n",
    "\n",
    "    sorted_df=df.sort_values(by = str(sample_label)+' exp. diff', ascending=False)\n",
    "    Closest_x_sim_trees = sorted_df[0:threshold]\n",
    "    params_of_closest_trees = Closest_x_sim_trees['params_label'].tolist()\n",
    "    params_label_counted = Counter(params_of_closest_trees)\n",
    "    \n",
    "    average_s = params_label_counted['s0/mu10minus5']*0+params_label_counted['s3/mu10minus5']*3+params_label_counted['s6/mu10minus5']*6+\\\n",
    "    params_label_counted['s9/mu10minus5']*9+params_label_counted['s12/mu10minus5']*12+\\\n",
    "    params_label_counted['s15/mu10minus5']*15+params_label_counted['s18/mu10minus5']*18+params_label_counted['s21/mu10minus5']*21+\\\n",
    "    params_label_counted['s24/mu10minus5']*24+params_label_counted['s27/mu10minus5']*27+params_label_counted['s30/mu10minus5']*30\n",
    "    Count_array = []\n",
    "    for s in [0,0.03,0.06,0.09,0.12,0.15,0.18, 0.21,0.24,0.27,0.30]:\n",
    "        mu_direction = []\n",
    "        for mu in [med,higher]:\n",
    "#             print(mapping[(s, mu)])\n",
    "            try:\n",
    "                entry= params_label_counted[mapping[(s, mu)]]\n",
    "            except:\n",
    "                entry = 0\n",
    "            mu_direction.append(entry)\n",
    "        Count_array.append(mu_direction)\n",
    " \n",
    "    y, x = np.meshgrid([med,higher], [0,0.03,0.06,0.09,0.12,0.15,0.18, 0.21,0.24,0.27,0.30])\n",
    "    y, x = np.meshgrid([med,higher], [0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    f, ax = plt.subplots(1,1, figsize=(2.5,2.5))\n",
    "    \n",
    "    font = {'weight' : 'normal','size'   : 25}\n",
    "    matplotlib.rc('font', **font)\n",
    "    f.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    for index, row in Closest_x_sim_trees.iterrows():\n",
    "        tree = [row['$f_0$'],row['$f_1$'],row['$f_2$'],row['$f_3$']]\n",
    "#         tree = [row['$f_0$'],row['$f_1$'],row['$f_2$']]\n",
    "        ax.plot(range(len(tree)), tree, color = grey2, zorder =0)\n",
    "        \n",
    "    ax.set_xticks(range(len(tree)))\n",
    "    ax.set_xticklabels(['$n_0$', '$n_1$', '$n_2$', '$n_3$'])\n",
    "#     ax.set_xticklabels(['', '', '', ''])\n",
    "    \n",
    "    real_tree =  [row1['$n_0$'],row1['$n_1$'],row1['$n_2$'],row1['$n_3$']]\n",
    "#     real_tree =  [row1['$f_0$'],row1['$f_1$'],row1['$f_2$'],row1['$f_3$']]\n",
    "\n",
    "    ax.plot([0,1,2,3], real_tree, label=sample_label, color = purple5, zorder = 1, linewidth=4)\n",
    "\n",
    "    ax.set_yticks([0,max(real_tree)])\n",
    "    ax.set_yticklabels(['0',round(max(real_tree),1)],fontsize=20)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    morita_sample_label =sample_label.split('-')\n",
    "    ax.set_title('morita-'+morita_sample_label[1], fontsize=20)\n",
    "#     ax.set_title(sample_label, fontsize=20)\n",
    "\n",
    "    \n",
    "#     plt.savefig('dataframes_for_distance_metrics/individual_tree_variation/with_6p/top_100/'+str(average_s)+'_k_4_'+str(sample_label)+'tree.pdf', bbox_inches = 'tight')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    f, ax = plt.subplots(1,1, figsize=(2.5,1))\n",
    "#     f, ax = plt.subplots(1,1, figsize=(14,2.5))\n",
    "    font = {'weight' : 'normal','size'   : 25}\n",
    "    matplotlib.rc('font', **font)\n",
    "    f.subplots_adjust(wspace=0.4)\n",
    "    \n",
    "    \n",
    "    c = ax.pcolormesh(x, y, Count_array, cmap='copper',vmax=50)\n",
    "#     ax[1].set_title('Underlying parameter space')\n",
    "#     ax.set_xlabel('$s$', fontsize = 30)\n",
    "#     ax[1].set_ylabel('$\\mu$', fontsize = 21)\n",
    "    ax.set_ylim(-5.5,-4.5)\n",
    "    \n",
    "    y_major_ticks = []\n",
    "    y_major_tick_labels = []\n",
    "    x_major_ticks = []\n",
    "    x_major_tick_labels = []\n",
    "#     x_major_ticks = [0, 1,2,3,4,5,6,7,8,9,10]\n",
    "#     x_major_tick_labels = [\"0%\", \"3%\", \"6%\", \"9%\", \"12%\", \"15%\", \"18%\",  \"21%\", \"24%\", \"27%\",  \"30%\"]\n",
    "\n",
    "    ax.set_yticks(y_major_ticks)\n",
    "    ax.set_yticklabels(y_major_tick_labels)\n",
    "    ax.set_xticks(x_major_ticks)\n",
    "#     ax.set_xticklabels(x_major_tick_labels, fontsize=30)\n",
    "    ax.margins(x=0)\n",
    "    # set the limits of the plot to the limits of the data\n",
    "    # ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "#     plt.colorbar(c, ax=ax, label= '# of simulated trees')\n",
    "#     plt.colorbar.ax.set_ylabel()\n",
    "    \n",
    "    \n",
    "#     break\n",
    "#     plt.savefig('dataframes_for_distance_metrics/individual_tree_variation/with_6p/top_100/'+str(average_s)+'_k_4_'+str(sample_label)+'.pdf', bbox_inches = 'tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
